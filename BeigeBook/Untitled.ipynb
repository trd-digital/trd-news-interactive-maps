{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6eb6a3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0602ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from bs4 import BeautifulSoup\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import requests\n",
    "import googlemaps\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials# Define the scope of the application\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "import googleapiclient.errors\n",
    "import bleach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0fee82",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37376a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "\n",
    "# Add credentials to the account\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('autoscraper-380600-0d0c84856d6b.json', scope)\n",
    "\n",
    "# Authorize the clientsheet \n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "sheet = client.open_by_key('11UHXwJ_A9-kJZANhI3JvqKBGhIlGilmaAuX7NVL7YA4')\n",
    "\n",
    "# Drive client\n",
    "drivesvc = build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "range_name = 'A1:AO200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80833b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(sheet, worksheet_name, range_name, df_name=None):\n",
    "    print('Fetching data from Google Sheets...')\n",
    "    worksheet = sheet.worksheet(worksheet_name)\n",
    "    data = worksheet.get(range_name)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = df.iloc[0]  # Set first row as column headers\n",
    "    df = df.drop(0).reset_index(drop=True)  # Drop the header row from the dataframe and reset index\n",
    "\n",
    "    df.drop_duplicates(inplace=True)  # Drop duplicate rows\n",
    "    print(f'Number of rows in {worksheet_name} worksheet: {len(df)}')\n",
    "    return df\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# HELPERS\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def extract_doc_id(url: str) -> str:\n",
    "    \"\"\"Extract the Doc ID from a Google Docs URL.\"\"\"\n",
    "    m = re.search(r\"/d/([a-zA-Z0-9_-]+)\", url)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unable to parse document ID from URL: {url}\")\n",
    "    return m.group(1)\n",
    "\n",
    "def export_doc_html(doc_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Export a Google Doc as HTML via Drive API and return\n",
    "    just the <body> contents (preserves paragraphs, bold, links, etc).\n",
    "    \"\"\"\n",
    "    html_bytes = drivesvc.files().export(\n",
    "        fileId=doc_id,\n",
    "        mimeType=\"text/html\"\n",
    "    ).execute()\n",
    "    soup = BeautifulSoup(html_bytes, \"html.parser\")\n",
    "    # Grab only the inner <body> so we don’t pull in full <head>, styles, etc.\n",
    "    return \"\".join(str(el) for el in soup.body.contents).strip()\n",
    "\n",
    "def geocode(address: str, api_key: str) -> tuple:\n",
    "    \"\"\"Return (lat, lon) for a given address using Google Maps Geocoding API.\"\"\"\n",
    "    endpoint = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    resp = requests.get(endpoint, params={\"address\": address, \"key\": api_key})\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    if data.get(\"status\") != \"OK\" or not data.get(\"results\"):\n",
    "        raise ValueError(f\"Geocoding failed for '{address}': {data.get('status')}\")\n",
    "    loc = data[\"results\"][0][\"geometry\"][\"location\"]\n",
    "    return loc[\"lat\"], loc[\"lng\"]\n",
    "\n",
    "def set_target_blank(attrs, new=False):\n",
    "    # attrs is a dict of existing a-tag attrs; we override/add target.\n",
    "    attrs[\"target\"] = \"_blank\"\n",
    "    return attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ecf288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from Google Sheets...\n",
      "Number of rows in Sheet1 worksheet: 18\n"
     ]
    }
   ],
   "source": [
    "df = fetch_data(sheet, 'Sheet1', range_name, 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f136b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r google_maps_API_Key\n",
    "# geocode each Metro once, via googlemaps.Client:\n",
    "gmaps = google_maps_API_Key = googlemaps.Client(key=google_maps_API_Key)\n",
    "df['geocoded'] = df['Metro'].apply(lambda m: gmaps.geocode(m)[0]['geometry']['location'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0805fab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: New York\n",
      "Processing: South Florida\n",
      "Processing: Los Angeles\n",
      "Processing: Chicago\n",
      "Processing: San Francisco (and San Jose/Silicon Valley)\n",
      "Processing: Texas (Dallas, Houston, Austin, San Antonio)\n",
      "Processing: Boston\n",
      "Processing: Washington, D.C.\n",
      "Processing: Philadelphia\n",
      "Processing: Atlanta\n",
      "Processing: Tampa\n",
      "Processing: Orlando\n",
      "Processing: Charlotte\n",
      "Processing: Nashville\n",
      "Processing: Phoenix\n",
      "Processing: Seattle\n",
      "Processing: Denver\n",
      "Processing: Las Vegas\n",
      "Wrote 18 features\n"
     ]
    }
   ],
   "source": [
    "import bleach\n",
    "from bs4 import BeautifulSoup\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "#  CONFIG: what to keep\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "ALLOWED_TAGS = [\"b\", \"strong\", \"i\", \"em\", \"br\", \"p\", \"a\"]\n",
    "ALLOWED_ATTRS = { \"a\": [\"href\", \"title\", \"target\"] }\n",
    "\n",
    "records = []\n",
    "for _, row in df.iterrows():\n",
    "    metro    = row[\"Metro\"]\n",
    "    doc_url  = row[\"Overview Draft Doc\"]\n",
    "    lat, lon = row[\"geocoded\"]\n",
    "    print(f\"Processing: {metro}\")\n",
    "\n",
    "    # 1) pull raw HTML\n",
    "    doc_id = extract_doc_id(doc_url)\n",
    "    raw    = export_doc_html(doc_id)\n",
    "\n",
    "    # 2) strip out everything except bold, italics, p, br, a[href]\n",
    "    clean = bleach.clean(\n",
    "        raw,\n",
    "        tags=ALLOWED_TAGS,\n",
    "        attributes=ALLOWED_ATTRS,\n",
    "        strip=True\n",
    "    )\n",
    "\n",
    "    # 3) parse & force all <a> to open in a new tab\n",
    "    soup = BeautifulSoup(clean, \"html.parser\")\n",
    "    for a in soup.find_all(\"a\"):\n",
    "        a[\"target\"] = \"_blank\"\n",
    "    clean = str(soup)\n",
    "\n",
    "    # 4) append your record\n",
    "    records.append({\n",
    "        \"Metro\":           metro,\n",
    "        \"Landing Page\":    row[\"Landing Page\"],\n",
    "        \"summary\":         clean,\n",
    "        \"Last Updated\":    row[\"Last Updated\"],\n",
    "        \"Last Updated By\": row[\"Last Updated By\"],\n",
    "        \"geometry\":        Point(lon, lat)\n",
    "    })\n",
    "\n",
    "if not records:\n",
    "    raise RuntimeError(\"No records!\")\n",
    "\n",
    "# build GeoDataFrame straight from records\n",
    "gdf = gpd.GeoDataFrame(records, crs=\"EPSG:4326\")\n",
    "gdf.to_file(\"market_overviews.geojson\", driver=\"GeoJSON\")\n",
    "print(f\"Wrote {len(gdf)} features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
