{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca6f4d9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65ebd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from bs4 import BeautifulSoup\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import requests\n",
    "import googlemaps\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials# Define the scope of the application\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "import googleapiclient.errors\n",
    "import bleach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32d2e7",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1597c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "\n",
    "# Add credentials to the account\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('autoscraper-380600-0d0c84856d6b.json', scope)\n",
    "\n",
    "# Authorize the clientsheet \n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "sheet = client.open_by_key('11UHXwJ_A9-kJZANhI3JvqKBGhIlGilmaAuX7NVL7YA4')\n",
    "\n",
    "# Drive client\n",
    "drivesvc = build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "range_name = 'A1:AO200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86428cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(sheet, worksheet_name, range_name, df_name=None):\n",
    "    print('Fetching data from Google Sheets...')\n",
    "    worksheet = sheet.worksheet(worksheet_name)\n",
    "    data = worksheet.get(range_name)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = df.iloc[0]  # Set first row as column headers\n",
    "    df = df.drop(0).reset_index(drop=True)  # Drop the header row from the dataframe and reset index\n",
    "\n",
    "    df.drop_duplicates(inplace=True)  # Drop duplicate rows\n",
    "    print(f'Number of rows in {worksheet_name} worksheet: {len(df)}')\n",
    "    return df\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# HELPERS\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def extract_doc_id(url: str) -> str:\n",
    "    \"\"\"Extract the Doc ID from a Google Docs URL.\"\"\"\n",
    "    m = re.search(r\"/d/([a-zA-Z0-9_-]+)\", url)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unable to parse document ID from URL: {url}\")\n",
    "    return m.group(1)\n",
    "\n",
    "def export_doc_html(doc_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Export a Google Doc as HTML via Drive API and return\n",
    "    just the <body> contents (preserves paragraphs, bold, links, etc).\n",
    "    \"\"\"\n",
    "    html_bytes = drivesvc.files().export(\n",
    "        fileId=doc_id,\n",
    "        mimeType=\"text/html\"\n",
    "    ).execute()\n",
    "    soup = BeautifulSoup(html_bytes, \"html.parser\")\n",
    "    # Grab only the inner <body> so we don’t pull in full <head>, styles, etc.\n",
    "    return \"\".join(str(el) for el in soup.body.contents).strip()\n",
    "\n",
    "def geocode(address: str, api_key: str) -> tuple:\n",
    "    \"\"\"Return (lat, lon) for a given address using Google Maps Geocoding API.\"\"\"\n",
    "    endpoint = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    resp = requests.get(endpoint, params={\"address\": address, \"key\": api_key})\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    if data.get(\"status\") != \"OK\" or not data.get(\"results\"):\n",
    "        raise ValueError(f\"Geocoding failed for '{address}': {data.get('status')}\")\n",
    "    loc = data[\"results\"][0][\"geometry\"][\"location\"]\n",
    "    return loc[\"lat\"], loc[\"lng\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c2ae20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from Google Sheets...\n",
      "Number of rows in Sheet1 worksheet: 18\n"
     ]
    }
   ],
   "source": [
    "df = fetch_data(sheet, 'Sheet1', range_name, 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30255c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r google_maps_API_Key\n",
    "# geocode each Metro once, via googlemaps.Client:\n",
    "gmaps = google_maps_API_Key = googlemaps.Client(key=google_maps_API_Key)\n",
    "df['geocoded'] = df['Metro'].apply(lambda m: gmaps.geocode(m)[0]['geometry']['location'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ae6c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing New York\n",
      "Processing South Florida\n",
      "Processing Los Angeles\n",
      "Processing Chicago\n",
      "Processing San Francisco (and San Jose/Silicon Valley)\n",
      "Processing Texas (Dallas, Houston, Austin, San Antonio)\n",
      "Processing Boston\n",
      "Processing Washington, D.C.\n",
      "Processing Philadelphia\n",
      "Processing Atlanta\n",
      "Processing Tampa\n",
      "Processing Orlando\n",
      "Processing Charlotte\n",
      "Processing Nashville\n",
      "Processing Phoenix\n",
      "Processing Seattle\n",
      "Processing Denver\n",
      "Processing Las Vegas\n",
      "Wrote 18 features\n"
     ]
    }
   ],
   "source": [
    "# 1) Define exactly which tags & attributes you want to keep\n",
    "ALLOWED_TAGS = [\n",
    "    \"b\", \"strong\",     # bold\n",
    "    \"i\", \"em\",         # italics\n",
    "    \"br\",              # explicit line‐breaks\n",
    "    \"p\",               # paragraphs (gives natural breaks)\n",
    "    \"a\"                # hyperlinks\n",
    "]\n",
    "ALLOWED_ATTRS = {\n",
    "    \"a\": [\"href\", \"title\", \"target\"]   # only allow these on <a>\n",
    "}\n",
    "\n",
    "\n",
    "records = []\n",
    "for _, row in df.iterrows():\n",
    "    metro    = row['Metro']\n",
    "    doc_url  = row['Overview Draft Doc']\n",
    "    lat, lon = row['geocoded']           # unpack here\n",
    "\n",
    "    print(f\"Processing: {metro}\")\n",
    "    doc_id      = extract_doc_id(doc_url)\n",
    "    raw = export_doc_html(doc_id)\n",
    "    \n",
    "    # 3) Clean it down to just your whitelist\n",
    "    clean = bleach.clean(\n",
    "        raw,\n",
    "        tags=ALLOWED_TAGS,\n",
    "        attributes=ALLOWED_ATTRS,\n",
    "        strip=True        # strip out disallowed tags entirely\n",
    "    )\n",
    "\n",
    "    records.append({\n",
    "        'Metro':            metro,\n",
    "        'Landing Page':     row['Landing Page'],\n",
    "        'summary':          clean,\n",
    "        'Last Updated':     row['Last Updated'],\n",
    "        'Last Updated By':  row['Last Updated By'],\n",
    "        'geometry':         Point(lon, lat)   # now lat/lon are defined\n",
    "    })\n",
    "\n",
    "if not records:\n",
    "    raise RuntimeError(\"No records!\")\n",
    "\n",
    "# build GeoDataFrame straight from records\n",
    "gdf = gpd.GeoDataFrame(records, crs=\"EPSG:4326\")\n",
    "gdf.to_file(\"market_overviews.geojson\", driver=\"GeoJSON\")\n",
    "print(f\"Wrote {len(gdf)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9462537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the geocode function\n",
    "# def geocode(add):\n",
    "#     g = GOOGLE_MAPS_API_KEY.geocode(add)\n",
    "#     if g:\n",
    "#         lat = g[0][\"geometry\"][\"location\"][\"lat\"]\n",
    "#         lng = g[0][\"geometry\"][\"location\"][\"lng\"]\n",
    "#         return (lat, lng)\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # Apply geocoding to the 'geo_address' column and store the results in 'geocoded' column\n",
    "# df['geocoded'] = df['Metro'].apply(geocode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f84a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ────────────────────────────────────────────────────────────────\n",
    "# #  PROCESS EACH DOC & BUILD RECORDS\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# records = []\n",
    "# for _, row in df.iterrows():\n",
    "#     metro = row['Metro']\n",
    "#     doc_url = row['Overview Draft Doc']\n",
    "#     geocoded = row['geocoded']\n",
    "#     last_updated_date = row['Last Updated'],\n",
    "#     last_updated_author = row['Last Updated By']\n",
    "#     print(f\"Processing metro: {metro}\")\n",
    "\n",
    "#     # 1) extract Doc ID and export as HTML\n",
    "#     doc_id = extract_doc_id(doc_url)\n",
    "#     html_bytes = drivesvc.files().export(\n",
    "#         fileId=doc_id,\n",
    "#         mimeType=\"text/html\"\n",
    "#     ).execute()\n",
    "#     soup = BeautifulSoup(html_bytes, 'html.parser')\n",
    "#     body = soup.body\n",
    "#     summary_html = ''.join(str(el) for el in body.contents).strip()\n",
    "\n",
    "#     records.append({\n",
    "#         'Metro':            metro,\n",
    "#         'Landing Page':     row['Landing Page'],\n",
    "#         'summary':          summary_html,        # ← your HTML string here\n",
    "#         'Last Updated':     row['Last Updated'],\n",
    "#         'Last Updated By':  row['Last Updated By'],\n",
    "#         'geometry':         Point(lng, lat)      # ← proper geometry\n",
    "#     })\n",
    "\n",
    "\n",
    "# if not records:\n",
    "#     raise ValueError(\"No records processed. Check your DOC_LINKS_CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3549283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_GEOJSON = \"market_overviews.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dffa315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ────────────────────────────────────────────────────────────────\n",
    "# #  BUILD GEOJSON\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# gdf = gpd.GeoDataFrame(\n",
    "#     records,\n",
    "#     geometry=[ Point(lon, lat) for lat, lon in df['geocoded'] ],\n",
    "#     crs=\"EPSG:4326\"\n",
    "# )\n",
    "\n",
    "# gdf.to_file(f\"{OUTPUT_GEOJSON}.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "# print(f\"GeoJSON with {len(gdf)} features written to {OUTPUT_GEOJSON}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
